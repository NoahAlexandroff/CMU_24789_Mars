{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Depth_Estimation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_4zknCd6uTC",
        "outputId": "73d409a7-de28-48b4-a685-057a79e2d77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install open3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miaxW2q77o_A",
        "outputId": "b96c4e59-d71b-41ca-d902-bcc78f2a98b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: open3d in /usr/local/lib/python3.7/dist-packages (0.15.2)\n",
            "Requirement already satisfied: pillow>=8.2.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (9.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.21.6)\n",
            "Requirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (7.7.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (62.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from open3d) (4.64.0)\n",
            "Requirement already satisfied: jupyterlab==3.*,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (3.4.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (1.3.5)\n",
            "Requirement already satisfied: jupyter-packaging~=0.10 in /usr/local/lib/python3.7/dist-packages (from open3d) (0.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from open3d) (6.0)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from open3d) (2.4.0)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.7/dist-packages (from open3d) (2.12.0)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.7/dist-packages (from open3d) (0.9.9)\n",
            "Requirement already satisfied: wheel>=0.36.0 in /usr/local/lib/python3.7/dist-packages (from open3d) (0.37.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.7/dist-packages (from open3d) (3.2.2)\n",
            "Requirement already satisfied: jupyterlab-server~=2.10 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (2.13.0)\n",
            "Requirement already satisfied: jinja2>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (4.10.0)\n",
            "Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (6.1)\n",
            "Requirement already satisfied: nbclassic~=0.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (0.3.7)\n",
            "Requirement already satisfied: jupyter-server~=1.16 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (21.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.*,>=3.0.0->open3d) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (1.1.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (5.3.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (3.6.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->open3d) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (7.3.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.7.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.1->jupyterlab==3.*,>=3.0.0->open3d) (2.0.1)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.7/dist-packages (from jupyter-packaging~=0.10->open3d) (0.10.2)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.7/dist-packages (from jupyter-packaging~=0.10->open3d) (2.1.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.8.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (3.5.0)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (6.5.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (22.3.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.3.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (21.3.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.14.1)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.13.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (4.2.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (2.8.2)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->open3d) (1.5.5)\n",
            "Requirement already satisfied: json5 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (0.9.7)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (2.23.0)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (4.3.3)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (2.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (3.8.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (5.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (21.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3->open3d) (3.0.8)\n",
            "Requirement already satisfied: notebook-shim>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.*,>=3.0.0->open3d) (0.1.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.*,>=3.0.0->open3d) (5.3.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.6.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (5.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (4.6.3)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.1.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.2.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.6.0->open3d) (2.15.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->open3d) (2022.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.*,>=3.0.0->open3d) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.*,>=3.0.0->open3d) (0.2.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->open3d) (3.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (2.21)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.16->jupyterlab==3.*,>=3.0.0->open3d) (0.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.10->jupyterlab==3.*,>=3.0.0->open3d) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "import os\n",
        "import glob\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import open3d as o3d\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class AI4MarsDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    A dataset class for the AI4Mars MSL data. It includes the grayscale images, depth data, and semantic labels.\n",
        "    Parameters:\n",
        "    -----------\n",
        "    folder_path: the path to the MSL directory of the AI4Mars dataset\n",
        "    is_train: True/False whether the dataset should be for the training or testing data\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, folder_path, is_train, image_size=256):\n",
        "        super(AI4MarsDataset, self).__init__()\n",
        "        self.image_size = image_size\n",
        "        self.img_files = []\n",
        "        self.depth_files = []\n",
        "        self.label_files = []\n",
        "        if is_train:\n",
        "            all_label_files = glob.glob(os.path.join(folder_path,'labels','train','*.png'))\n",
        "        else:\n",
        "            all_label_files = glob.glob(os.path.join(folder_path,'labels','test','masked-gold-min1-100agree','*.png'))\n",
        "        for label_path in all_label_files:\n",
        "            if is_train: \n",
        "                base_name = os.path.basename(label_path)[:-4]\n",
        "            else:\n",
        "                base_name = os.path.basename(label_path)[:-11]\n",
        "            depth_path = os.path.join(folder_path,'images','rng_256',base_name[0:13]+'RNG'+base_name[16:]+\".tiff\")\n",
        "            image_path = os.path.join(folder_path,'images','edr',base_name+\".JPG\")\n",
        "            if os.path.exists(depth_path) and os.path.exists(image_path):\n",
        "                self.img_files.append(image_path)\n",
        "                self.depth_files.append(depth_path)\n",
        "                self.label_files.append(label_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_size = self.image_size\n",
        "        img_path = self.img_files[index]\n",
        "        label_path = self.label_files[index]\n",
        "        depth_path = self.depth_files[index]\n",
        "        image = Image.open(img_path)\n",
        "        depth = Image.open(depth_path)\n",
        "        label = Image.open(label_path)\n",
        "        image = image.resize((image_size,image_size),Image.ANTIALIAS)\n",
        "        depth = depth.resize((image_size,image_size),Image.ANTIALIAS)\n",
        "        label = label.resize((image_size,image_size),Image.NEAREST)\n",
        "        image = np.asarray(image)\n",
        "        depth = np.asarray(depth)\n",
        "        label = np.asarray(label)\n",
        "        image = torch.from_numpy(image).float()\n",
        "        depth = torch.from_numpy(depth).float()\n",
        "        label = torch.from_numpy(label).long()\n",
        "        \n",
        "        return image, depth, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def display_image(self, index):\n",
        "        image_size = self.image_size\n",
        "        img_path = self.img_files[index]\n",
        "        depth_path = self.depth_files[index]\n",
        "        image = Image.open(img_path)\n",
        "        depth = Image.open(depth_path)\n",
        "        image = image.resize((image_size,image_size),Image.ANTIALIAS)\n",
        "        depth = depth.resize((image_size,image_size),Image.ANTIALIAS)\n",
        "        image = np.ascontiguousarray(image, dtype=np.float32).reshape(image_size,image_size,1)\n",
        "        depth = np.ascontiguousarray(depth, dtype=np.float32).reshape(image_size,image_size,1)\n",
        "        color_raw = o3d.geometry.Image(image)\n",
        "        depth_raw = o3d.geometry.Image(depth)\n",
        "        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_raw, depth_raw)\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title('Grayscale Image')\n",
        "        plt.imshow(rgbd_image.color)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title('Depth Image')\n",
        "        plt.imshow(rgbd_image.depth)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "BGBkwGke7iBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "     \n",
        "    def forward(self, x):\n",
        "        return self.conv_block(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x1 = self.maxpool(x)\n",
        "        x2 = self.conv_block(x1)\n",
        "\n",
        "        return x2\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "            super().__init__()\n",
        "\n",
        "            self.upscale = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv_block = ConvBlock(in_channels, out_channels)\n",
        "\n",
        "    \n",
        "    def forward(self, x, enc_x):\n",
        "        x1 = self.upscale(x)\n",
        "\n",
        "        delta_Y = enc_x.size()[2] - x1.size()[2]\n",
        "        delta_X = enc_x.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [delta_X // 2, delta_X - delta_X // 2,\n",
        "                        delta_Y // 2, delta_Y - delta_Y // 2])\n",
        "        \n",
        "        x1 = torch.cat([enc_x,x1], dim=1)\n",
        "\n",
        "        x2 = self.conv_block(x1)\n",
        "\n",
        "        return x2 \n",
        "    \n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        \n",
        "        self.enc0= ConvBlock(in_channels, 64)\n",
        "        self.enc1 = Encoder(64, 128)\n",
        "        self.enc2 = Encoder(128, 256)\n",
        "        self.enc3 = Encoder(256, 512)\n",
        "        self.enc4 = Encoder(512, 1024)\n",
        "        self.dec1 = Decoder(1024, 512)\n",
        "        self.dec2 = Decoder(512, 256)\n",
        "        self.dec3 = Decoder(256, 128)\n",
        "        self.dec4 = Decoder(128, 64)\n",
        "        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.enc0(x)\n",
        "        x2 = self.enc1(x1)\n",
        "        x3 = self.enc2(x2)\n",
        "        x4 = self.enc3(x3)\n",
        "        x5 = self.enc4(x4)\n",
        "        x = self.dec1(x5, x4)\n",
        "        x = self.dec2(x, x3)\n",
        "        x = self.dec3(x, x2)\n",
        "        x = self.dec4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "X6VbgNm78FWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import os, time\n",
        "import shutil\n",
        "import sys\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import random"
      ],
      "metadata": {
        "id": "j6iGwu1zSTwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU4WcebzHyEb",
        "outputId": "d2c2a43d-f3a0-45d5-c00e-2dbff3bb43d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.8.2)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (0.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics"
      ],
      "metadata": {
        "id": "keWYQjfAH7WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "Eji063UE8MFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Pillow==9.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMtO2GfiWCn5",
        "outputId": "5b5cf096-069b-4b4f-f73f-29c0d607f9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow==9.0.0 in /usr/local/lib/python3.7/dist-packages (9.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(num_epochs=5, batch_size=2, dataroot=\"/content/drive/MyDrive/data/data_subset/msl\", image_size = 256):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if device == torch.device('cpu'):\n",
        "        num_workers = 0\n",
        "    else:\n",
        "        torch.cuda.empty_cache()\n",
        "        num_workers = 2\n",
        "    # load and transform dataset\n",
        "\n",
        "    train_dataset = AI4MarsDataset(folder_path=dataroot, is_train=True, image_size=image_size)\n",
        "    test_dataset = AI4MarsDataset(folder_path=dataroot, is_train=False, image_size=image_size)\n",
        "\n",
        "    train_size = int(256/256 * len(train_dataset))\n",
        "    eval_size = len(train_dataset) - train_size\n",
        "    train_dataset, eval_dataset = torch.utils.data.random_split(train_dataset, [train_size, eval_size])\n",
        "    \n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=num_workers)\n",
        "    evalloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size,\n",
        "                                              shuffle=False, num_workers=num_workers)\n",
        "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                             shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    model = UNet(in_channels=1,n_classes=1)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    model.to(device)\n",
        "    best_model_test_acc = 0\n",
        "    \n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        train_loss, test_loss = 0.0, 0.0\n",
        "        train_acc, test_acc = 0.0, 0.0\n",
        "        train_total, test_total = 0, 0\n",
        "        train_correct, test_correct = 0, 0\n",
        "        model.train()\n",
        "        \n",
        "        for data in trainloader:\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            images, depths, labels = data\n",
        "            num_in_batch = images.shape[0]\n",
        "            images=images.reshape(num_in_batch,1,image_size,image_size)\n",
        "            depths=depths.reshape(num_in_batch,1,image_size,image_size)\n",
        "            labels = labels.reshape(num_in_batch,image_size,image_size).long()\n",
        "            labels[labels>=255]=4\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(images.to(device))\n",
        "            train_loss = criterion(outputs, depths.to(device))\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            train_loss += train_loss.item()\n",
        "        with torch.no_grad():\n",
        "          model.eval()\n",
        "          for data in testloader:\n",
        "                images, depths, labels = data\n",
        "                num_in_batch = images.shape[0]\n",
        "                images=images.reshape(num_in_batch,1,image_size,image_size)\n",
        "                depths=depths.reshape(num_in_batch,1,image_size,image_size)\n",
        "                labels = labels.reshape(num_in_batch,image_size,image_size).long()\n",
        "                labels[labels==255]=4\n",
        "                outputs = model(images.to(device))\n",
        "                test_loss = criterion(outputs, depths.to(device))\n",
        "                test_loss += test_loss.item()\n",
        "        print('Epoch %d| Train loss: %.4f|Test loss: %.4f|'%(\n",
        "            epoch+1, train_loss/len(trainloader), test_loss/len(testloader)))\n",
        "        \n",
        "        torch.save(model.state_dict(), './model.pth')\n",
        "          \n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuKH_vbDUq54",
        "outputId": "ac437ed0-97b3-46f6-cd71-6caa810eb64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1| Train loss: 2.5758|Test loss: 4.2758|\n",
            "Epoch 2| Train loss: 1.2660|Test loss: 3.8343|\n",
            "Epoch 3| Train loss: 1.0599|Test loss: 3.9559|\n",
            "Epoch 4| Train loss: 0.6707|Test loss: 3.4649|\n",
            "Epoch 5| Train loss: 0.5434|Test loss: 2.3009|\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(num_epochs=5, batch_size=2, dataroot=\"/content/drive/MyDrive/data/data_subset/msl\", image_size = 256):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if device == torch.device('cpu'):\n",
        "        num_workers = 0\n",
        "    else:\n",
        "        torch.cuda.empty_cache()\n",
        "        num_workers = 2\n",
        "    # load and transform dataset\n",
        "\n",
        "    train_dataset = AI4MarsDataset(folder_path=dataroot, is_train=True, image_size=image_size)\n",
        "    test_dataset = AI4MarsDataset(folder_path=dataroot, is_train=False, image_size=image_size)\n",
        "\n",
        "    train_size = int(256/256 * len(train_dataset))\n",
        "    eval_size = len(train_dataset) - train_size\n",
        "    train_dataset, eval_dataset = torch.utils.data.random_split(train_dataset, [train_size, eval_size])\n",
        "    \n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=num_workers)\n",
        "    evalloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size,\n",
        "                                              shuffle=False, num_workers=num_workers)\n",
        "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                             shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    model = UNet(in_channels=1,n_classes=1)\n",
        "    criterion = nn.L1Loss()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    model.to(device)\n",
        "    best_model_test_acc = 0\n",
        "    \n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        train_loss, test_loss = 0.0, 0.0\n",
        "        train_acc, test_acc = 0.0, 0.0\n",
        "        train_total, test_total = 0, 0\n",
        "        train_correct, test_correct = 0, 0\n",
        "        model.train()\n",
        "        \n",
        "        for data in trainloader:\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            images, depths, labels = data\n",
        "            num_in_batch = images.shape[0]\n",
        "            images=images.reshape(num_in_batch,1,image_size,image_size)\n",
        "            depths=depths.reshape(num_in_batch,1,image_size,image_size)\n",
        "            labels = labels.reshape(num_in_batch,image_size,image_size).long()\n",
        "            labels[labels>=255]=4\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(images.to(device))\n",
        "            train_loss = criterion(outputs, depths.to(device))\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            train_loss += train_loss.item()\n",
        "        with torch.no_grad():\n",
        "          model.eval()\n",
        "          for data in testloader:\n",
        "                images, depths, labels = data\n",
        "                num_in_batch = images.shape[0]\n",
        "                images=images.reshape(num_in_batch,1,image_size,image_size)\n",
        "                depths=depths.reshape(num_in_batch,1,image_size,image_size)\n",
        "                labels = labels.reshape(num_in_batch,image_size,image_size).long()\n",
        "                labels[labels==255]=4\n",
        "                outputs = model(images.to(device))\n",
        "                test_loss = criterion(outputs, depths.to(device))\n",
        "                test_loss += test_loss.item()\n",
        "        print('Epoch %d| Train loss: %.4f|Test loss: %.4f|'%(\n",
        "            epoch+1, train_loss/len(trainloader), test_loss/len(testloader)))\n",
        "        \n",
        "        torch.save(model.state_dict(), './model.pth')\n",
        "          \n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oosdzWAIaVJr",
        "outputId": "20c6bfdd-847b-4646-af51-eb6cff3cb265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1| Train loss: 0.0467|Test loss: 0.1014|\n",
            "Epoch 2| Train loss: 0.1125|Test loss: 0.0795|\n",
            "Epoch 3| Train loss: 0.0921|Test loss: 0.1187|\n",
            "Epoch 4| Train loss: 0.0614|Test loss: 0.0891|\n",
            "Epoch 5| Train loss: 0.0490|Test loss: 0.0698|\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSE(nn.Module):\n",
        "    def _init_(self):\n",
        "        super(RMSE, self)._init_()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "\n",
        "        rmse = torch.sqrt(torch.mean(torch.pow(targets - preds, 2)))\n",
        "\n",
        "        return rmse"
      ],
      "metadata": {
        "id": "BYNaO9sQGei1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(num_epochs=5, batch_size=2, dataroot=\"/content/drive/MyDrive/data/data_subset/msl\", image_size = 256):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if device == torch.device('cpu'):\n",
        "        num_workers = 0\n",
        "    else:\n",
        "        torch.cuda.empty_cache()\n",
        "        num_workers = 2\n",
        "    # load and transform dataset\n",
        "\n",
        "    train_dataset = AI4MarsDataset(folder_path=dataroot, is_train=True, image_size=image_size)\n",
        "    test_dataset = AI4MarsDataset(folder_path=dataroot, is_train=False, image_size=image_size)\n",
        "\n",
        "    train_size = int(256/256 * len(train_dataset))\n",
        "    eval_size = len(train_dataset) - train_size\n",
        "    train_dataset, eval_dataset = torch.utils.data.random_split(train_dataset, [train_size, eval_size])\n",
        "    \n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=num_workers)\n",
        "    evalloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size,\n",
        "                                              shuffle=False, num_workers=num_workers)\n",
        "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                             shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    model = UNet(in_channels=1,n_classes=1)\n",
        "    criterion = RMSE()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    model.to(device)\n",
        "    best_model_test_acc = 0\n",
        "    \n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        train_loss, test_loss = 0.0, 0.0\n",
        "        train_acc, test_acc = 0.0, 0.0\n",
        "        train_total, test_total = 0, 0\n",
        "        train_correct, test_correct = 0, 0\n",
        "        model.train()\n",
        "        \n",
        "        for data in trainloader:\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            images, depths, labels = data\n",
        "            num_in_batch = images.shape[0]\n",
        "            images=images.reshape(num_in_batch,1,image_size,image_size)\n",
        "            depths=depths.reshape(num_in_batch,1,image_size,image_size)\n",
        "            labels = labels.reshape(num_in_batch,image_size,image_size).long()\n",
        "            labels[labels>=255]=4\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(images.to(device))\n",
        "            train_loss = criterion(depths.to(device),outputs)\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            train_loss += train_loss.item()\n",
        "        with torch.no_grad():\n",
        "          model.eval()\n",
        "          for data in testloader:\n",
        "                images, depths, labels = data\n",
        "                num_in_batch = images.shape[0]\n",
        "                images=images.reshape(num_in_batch,1,image_size,image_size)\n",
        "                depths=depths.reshape(num_in_batch,1,image_size,image_size)\n",
        "                labels = labels.reshape(num_in_batch,image_size,image_size).long()\n",
        "                labels[labels==255]=4\n",
        "                outputs = model(images.to(device))\n",
        "                test_loss = criterion(depths.to(device),outputs)\n",
        "                test_loss += test_loss.item()\n",
        "        print('Epoch %d| Train loss: %.4f|Test loss: %.4f|'%(\n",
        "            epoch+1, train_loss/len(trainloader), test_loss/len(testloader)))\n",
        "        \n",
        "        torch.save(model.state_dict(), './model.pth')\n",
        "          \n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eODevZYDTV7",
        "outputId": "682506de-dcd5-4fcd-dde2-8a88faa16474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1| Train loss: 0.0473|Test loss: 0.2363|\n",
            "Epoch 2| Train loss: 0.0899|Test loss: 0.2082|\n",
            "Epoch 3| Train loss: 0.1666|Test loss: 0.1886|\n",
            "Epoch 4| Train loss: 0.1079|Test loss: 0.1788|\n",
            "Epoch 5| Train loss: 0.0978|Test loss: 0.1876|\n",
            "Finished Training\n"
          ]
        }
      ]
    }
  ]
}